# Create mock importance data for logistic regression (based on z-values)
log_importance <- data.frame(
Variable = c("age_advantage", "striking_defense_diff", "R_avg_SIG_STR_pct",
"R_avg_TD_pct", "R_avg_SUB_ATT"),
Importance = c(9.775, 4.297, 2.638, 2.574, 2.413),
Model = "Logistic Regression"
)
# Create mock importance data for random forest (based on Mean Decrease Gini)
rf_importance <- data.frame(
Variable = c("offense_defense_diff", "age_advantage", "R_striking_to_grappling_ratio",
"striking_defense_diff", "B_striking_to_grappling_ratio",
"striking_accuracy_diff", "takedown_defense_diff",
"R_avg_SIG_STR_pct", "experience_diff", "takedown_accuracy_diff"),
Importance = c(88.79, 81.95, 76.50, 74.33, 70.78, 70.06, 68.60, 68.44, 64.43, 64.19),
Model = "Random Forest"
)
# Normalize importance scores for fair comparison
log_importance$Importance_Normalized <- log_importance$Importance / max(log_importance$Importance)
rf_importance$Importance_Normalized <- rf_importance$Importance / max(rf_importance$Importance)
# Select top features from both models
top_features <- unique(c(
log_importance$Variable,
rf_importance$Variable[1:10]
))
# Create a comparison data frame
importance_comparison <- data.frame(
Variable = top_features,
LogisticRegression = 0,
RandomForest = 0
)
# Fill in the normalized importance values
for (var in top_features) {
if (var %in% log_importance$Variable) {
importance_comparison$LogisticRegression[importance_comparison$Variable == var] <-
log_importance$Importance_Normalized[log_importance$Variable == var]
}
if (var %in% rf_importance$Variable) {
importance_comparison$RandomForest[importance_comparison$Variable == var] <-
rf_importance$Importance_Normalized[rf_importance$Variable == var]
}
}
# Reshape for plotting
importance_comparison_long <- importance_comparison %>%
pivot_longer(cols = c(LogisticRegression, RandomForest),
names_to = "Model",
values_to = "Importance")
# Create individual plots for each model
log_plot <- ggplot(log_importance %>% arrange(desc(Importance)),
aes(x = reorder(Variable, Importance), y = Importance)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Top Important Features (Logistic Regression)",
x = "Feature",
y = "Importance (|z-value|)") +
theme_minimal() +
theme(plot.title = element_text(size = 12, face = "bold"),
axis.text.y = element_text(size = 10))
rf_plot <- ggplot(rf_importance %>% head(10) %>% arrange(desc(Importance)),
aes(x = reorder(Variable, Importance), y = Importance)) +
geom_bar(stat = "identity", fill = "darkgreen") +
coord_flip() +
labs(title = "Top Important Features (Random Forest)",
x = "Feature",
y = "Importance (Mean Decrease Gini)") +
theme_minimal() +
theme(plot.title = element_text(size = 12, face = "bold"),
axis.text.y = element_text(size = 10))
# Create comparison plot
comparison_plot <- ggplot(importance_comparison_long,
aes(x = reorder(Variable, Importance),
y = Importance,
fill = Model)) +
geom_bar(stat = "identity", position = "dodge") +
coord_flip() +
scale_fill_manual(values = c("LogisticRegression" = "steelblue",
"RandomForest" = "darkgreen")) +
labs(title = "Variable Importance Comparison",
subtitle = "Normalized importance scores across both models",
x = "Feature",
y = "Normalized Importance") +
theme_minimal() +
theme(legend.position = "bottom",
plot.title = element_text(size = 14, face = "bold"),
axis.text.y = element_text(size = 10))
# Arrange plots side by side and below
grid.arrange(
arrangeGrob(log_plot, rf_plot, ncol = 2),
comparison_plot,
nrow = 2,
heights = c(1, 1.2)
)
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(lubridate)
# Assuming your dataframe is called ufc_clean_features
# First convert date to proper date format and extract year
ufc_data <- ufc_clean_features %>%
mutate(date = as.Date(date),
year = year(date)) %>%
# Count wins by year and corner
group_by(year) %>%
summarize(
red_wins = sum(Winner == "Red"),
total_fights = n(),
red_win_pct = red_wins / total_fights * 100,
.groups = "drop"
)
# Create the plot
ggplot(ufc_data, aes(x = year, y = red_win_pct)) +
geom_line(color = "black") +
geom_point(aes(size = total_fights), color = "black", alpha = 0.8) +
scale_size_continuous(range = c(3, 8), name = "Total Fights") +
scale_x_continuous(breaks = seq(min(ufc_data$year), max(ufc_data$year), by = 5)) +
scale_y_continuous(limits = c(50, 100), name = "Red (%)") +
labs(title = "Red Fighter Win Percentage by Year",
x = "Year") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0, face = "bold"),
legend.position = "right",
panel.grid.minor = element_blank()
)
# Assuming your dataframe is called ufc_clean_features
# First convert date to proper date format and extract year
ufc_data <- ufc_clean_features %>%
mutate(date = as.Date(date),
year = year(date)) %>%
# Count wins by year and corner
group_by(year) %>%
summarize(
red_wins = sum(Winner == "Red"),
total_fights = n(),
red_win_pct = red_wins / total_fights * 100,
.groups = "drop"
)
# Create the plot
ggplot(ufc_data, aes(x = year, y = red_win_pct)) +
geom_line(color = "black") +
geom_point(aes(size = total_fights), color = "black", alpha = 0.8) +
scale_size_continuous(range = c(3, 8), name = "Total Fights") +
scale_x_continuous(breaks = seq(min(ufc_data$year), max(ufc_data$year), by = 5)) +
scale_y_continuous(limits = c(50, 100), name = "Red (%)") +
labs(title = "Red Fighter Win Percentage by Year",
x = "Year") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0, face = "bold"),
legend.position = "right",
panel.grid.minor = element_blank()
)
# Assuming your dataframe is called ufc_clean_features
# First convert date to proper date format and extract year
ufc_data <- ufc_clean_features %>%
mutate(date = as.Date(date),
year = year(date)) %>%
# Count wins by year and corner
group_by(year) %>%
summarize(
red_wins = sum(Winner == "Red"),
total_fights = n(),
red_win_pct = red_wins / total_fights * 100,
.groups = "drop"
)
ufc_clean_features <- read.csv("data/ufc_clean_features.csv", stringsAsFactors = FALSE)
# Assuming your dataframe is called ufc_clean_features
# First convert date to proper date format and extract year
ufc_data <- ufc_clean_features %>%
mutate(date = as.Date(date),
year = year(date)) %>%
# Count wins by year and corner
group_by(year) %>%
summarize(
red_wins = sum(Winner == "Red"),
total_fights = n(),
red_win_pct = red_wins / total_fights * 100,
.groups = "drop"
)
# Create the plot
ggplot(ufc_data, aes(x = year, y = red_win_pct)) +
geom_line(color = "black") +
geom_point(aes(size = total_fights), color = "black", alpha = 0.8) +
scale_size_continuous(range = c(3, 8), name = "Total Fights") +
scale_x_continuous(breaks = seq(min(ufc_data$year), max(ufc_data$year), by = 5)) +
scale_y_continuous(limits = c(50, 100), name = "Red (%)") +
labs(title = "Red Fighter Win Percentage by Year",
x = "Year") +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0, face = "bold"),
legend.position = "right",
panel.grid.minor = element_blank()
)
# Load necessary libraries
library(tidyverse)
# Load necessary libraries
library(tidyverse)
library(lme4)      # For mixed-effects models
install.packages("lme4")
library(lme4)      # For mixed-effects models
library(lme4)      # For mixed-effects models
library(caret)     # For model evaluation
library(pROC)      # For ROC curves
library(effects)   # For plotting effects
install.packages("effects")
library(effects)   # For plotting effects
# Read the feature-engineered dataset
ufc_model_data <- read.csv("data/ufc_clean_features.csv", stringsAsFactors = FALSE)
# Step 1: Extract unique fighters and assign IDs
all_fighters <- unique(c(ufc_model_data$R_fighter, ufc_model_data$B_fighter))
fighter_ids <- data.frame(
fighter_name = all_fighters,
fighter_id = 1:length(all_fighters),
stringsAsFactors = FALSE
)
# Step 2: Map fighter IDs back to the dataset
ufc_model_data <- ufc_model_data %>%
left_join(fighter_ids, by = c("R_fighter" = "fighter_name")) %>%
rename(R_fighter_id = fighter_id) %>%
left_join(fighter_ids, by = c("B_fighter" = "fighter_name")) %>%
rename(B_fighter_id = fighter_id)
# Step 3: Select key predictors identified from previous models
# These should include the most important features from your previous analyses
key_predictors <- c(
# Physical advantages
"age_advantage", "reach_advantage",
# Performance differentials
"striking_accuracy_diff", "striking_defense_diff",
"takedown_accuracy_diff", "takedown_defense_diff",
"knockdown_diff", "submission_attempts_diff",
# Experience and record
"win_pct_advantage", "R_longest_win_streak", "B_longest_win_streak",
# Fighter style indicators
"R_offense_defense_ratio", "B_offense_defense_ratio"
)
# Step 4: Data preparation for mixed-effects modeling
model_data <- ufc_model_data %>%
select(R_fighter_id, B_fighter_id, all_of(key_predictors), target) %>%
# Convert target to factor for classification
mutate(target = as.factor(target))
# Step 5: Split data for training and testing
set.seed(123)
train_index <- createDataPartition(model_data$target, p = 0.8, list = FALSE)
train_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]
# Model 1: Random intercepts for red corner fighter
mixed_model_red <- glmer(
target ~ age_advantage + reach_advantage +
striking_accuracy_diff + striking_defense_diff +
takedown_accuracy_diff + takedown_defense_diff +
knockdown_diff + submission_attempts_diff +
win_pct_advantage +
(1|R_fighter_id),
data = train_data,
family = binomial,
control = glmerControl(optimizer = "bobyqa")
)
# Model 2: Random intercepts for both fighters
mixed_model_both <- glmer(
target ~ age_advantage + reach_advantage +
striking_accuracy_diff + striking_defense_diff +
takedown_accuracy_diff + takedown_defense_diff +
knockdown_diff + submission_attempts_diff +
win_pct_advantage +
(1|R_fighter_id) + (1|B_fighter_id),
data = train_data,
family = binomial,
control = glmerControl(optimizer = "bobyqa")
)
# Step 7: Model evaluation and comparison
# Summary of models
summary_red <- summary(mixed_model_red)
summary_both <- summary(mixed_model_both)
# Model comparison with AIC and BIC
model_comparison <- data.frame(
Model = c("Red Fighter Random Effect", "Both Fighters Random Effects"),
AIC = c(AIC(mixed_model_red), AIC(mixed_model_both)),
BIC = c(BIC(mixed_model_red), BIC(mixed_model_both))
)
# Step 8: Prediction on test set using the best model
# Using Model 2 (with both fighters) for prediction
pred_probs <- predict(mixed_model_both, newdata = test_data, type = "response", re.form = NULL)
pred_class <- ifelse(pred_probs > 0.5, 1, 0)
# Evaluate predictions
confusion_matrix <- confusionMatrix(factor(pred_class), test_data$target)
roc_result <- roc(as.numeric(test_data$target) - 1, pred_probs)
auc_value <- auc(roc_result)
# Step 8: Prediction on test set using the best model
# Using Model 2 (with both fighters) for prediction
pred_probs <- predict(mixed_model_both, newdata = test_data, type = "response", re.form = NULL)
# Load necessary libraries
library(tidyverse)
library(lme4)      # For mixed-effects models
library(caret)     # For model evaluation
library(pROC)      # For ROC curves
# Read the feature-engineered dataset
ufc_model_data <- read.csv("data/ufc_clean_features.csv", stringsAsFactors = FALSE)
# Step 1: Extract unique fighters and assign IDs
all_fighters <- unique(c(ufc_model_data$R_fighter, ufc_model_data$B_fighter))
fighter_ids <- data.frame(
fighter_name = all_fighters,
fighter_id = 1:length(all_fighters),
stringsAsFactors = FALSE
)
# Step 2: Map fighter IDs back to the dataset
ufc_model_data <- ufc_model_data %>%
left_join(fighter_ids, by = c("R_fighter" = "fighter_name")) %>%
rename(R_fighter_id = fighter_id) %>%
left_join(fighter_ids, by = c("B_fighter" = "fighter_name")) %>%
rename(B_fighter_id = fighter_id)
# Step 3: Select key predictors identified from previous models
key_predictors <- c(
# Physical advantages
"age_advantage", "reach_advantage",
# Performance differentials
"striking_accuracy_diff", "striking_defense_diff",
"takedown_accuracy_diff", "takedown_defense_diff",
"knockdown_diff", "submission_attempts_diff",
# Experience and record
"win_pct_advantage", "R_longest_win_streak", "B_longest_win_streak",
# Fighter style indicators
"R_offense_defense_ratio", "B_offense_defense_ratio"
)
# Step 4: Data preparation for mixed-effects modeling
model_data <- ufc_model_data %>%
select(R_fighter_id, B_fighter_id, all_of(key_predictors), target) %>%
# Convert target to factor for classification
mutate(target = as.factor(target))
# First, add a fight_id column to identify unique bouts
model_data$fight_id <- 1:nrow(model_data)
# Get list of all unique fighter IDs
all_fighter_ids <- unique(c(model_data$R_fighter_id, model_data$B_fighter_id))
# Identify which fights contain at least one fighter we want to keep in training set
# This ensures all fighters in test set have been seen in training
set.seed(123)  # For reproducibility
train_fighter_ids <- sample(all_fighter_ids, size = round(0.8 * length(all_fighter_ids)))
# Create training set with all fights containing at least one fighter from train_fighter_ids
train_data <- model_data %>%
filter(R_fighter_id %in% train_fighter_ids | B_fighter_id %in% train_fighter_ids)
# Create test set with remaining fights, but only those where both fighters appear in training
test_data <- model_data %>%
filter(!(fight_id %in% train_data$fight_id)) %>%
filter(R_fighter_id %in% train_fighter_ids & B_fighter_id %in% train_fighter_ids)
# Check if split was successful
cat("Training set size:", nrow(train_data), "fights\n")
cat("Test set size:", nrow(test_data), "fights\n")
# Step 6: Train mixed-effects model
# Using both fighters as random effects
mixed_model <- glmer(
target ~ age_advantage + reach_advantage +
striking_accuracy_diff + striking_defense_diff +
takedown_accuracy_diff + takedown_defense_diff +
knockdown_diff + submission_attempts_diff +
win_pct_advantage +
(1|R_fighter_id) + (1|B_fighter_id),
data = train_data,
family = binomial,
control = glmerControl(optimizer = "bobyqa")
)
# Step 6: Train mixed-effects model
# Using both fighters as random effects
mixed_model <- glmer(
target ~ age_advantage + reach_advantage +
striking_accuracy_diff + striking_defense_diff +
takedown_accuracy_diff + takedown_defense_diff +
knockdown_diff + submission_attempts_diff +
win_pct_advantage +
(1|R_fighter_id) + (1|B_fighter_id),
data = train_data,
family = binomial,
control = glmerControl(optimizer = "bobyqa")
)
# Step 7: Model summary
model_summary <- summary(mixed_model)
print(model_summary)
# Step 8: Prediction on test set
# Now this should work since all fighter IDs in test set are also in training set
pred_probs <- predict(mixed_model, newdata = test_data, type = "response")
pred_class <- ifelse(pred_probs > 0.5, 1, 0)
# Load necessary libraries
library(tidyverse)
library(lme4)      # For mixed-effects models
# Read the feature-engineered dataset
ufc_model_data <- read.csv("data/ufc_clean_features.csv", stringsAsFactors = FALSE)
# Convert date to Date type for temporal analysis
ufc_model_data$date <- as.Date(ufc_model_data$date)
# Step 1: Extract unique fighters and assign IDs
all_fighters <- unique(c(ufc_model_data$R_fighter, ufc_model_data$B_fighter))
fighter_ids <- data.frame(
fighter_name = all_fighters,
fighter_id = 1:length(all_fighters),
stringsAsFactors = FALSE
)
# Step 2: Map fighter IDs back to the dataset
ufc_model_data <- ufc_model_data %>%
left_join(fighter_ids, by = c("R_fighter" = "fighter_name")) %>%
rename(R_fighter_id = fighter_id) %>%
left_join(fighter_ids, by = c("B_fighter" = "fighter_name")) %>%
rename(B_fighter_id = fighter_id)
# Step 3: Select key predictors based on initial analysis
key_predictors <- c(
# Physical advantages
"age_advantage", "reach_advantage",
# Performance differentials
"striking_accuracy_diff", "striking_defense_diff",
"takedown_accuracy_diff", "takedown_defense_diff",
"knockdown_diff",
# Experience and record
"win_pct_advantage", "R_longest_win_streak", "experience_diff"
)
# Step 4: Prepare model dataset
model_data <- ufc_model_data %>%
select(R_fighter_id, B_fighter_id, all_of(key_predictors), target) %>%
mutate(target = as.factor(target))
# Step 5: Fit mixed-effects model
mixed_model <- glmer(
target ~ age_advantage + reach_advantage +
striking_accuracy_diff + striking_defense_diff +
takedown_accuracy_diff + takedown_defense_diff +
knockdown_diff + win_pct_advantage +
(1|R_fighter_id) + (1|B_fighter_id),
data = model_data,
family = binomial,
control = glmerControl(optimizer = "bobyqa")
)
# Step 6: Print model summary
summary_mixed <- summary(mixed_model)
print(summary_mixed)
# Step 7: Extract fighter-specific random effects
red_fighter_effects <- ranef(mixed_model)$R_fighter_id
blue_fighter_effects <- ranef(mixed_model)$B_fighter_id
# Step 8: Create dataframes with fighter IDs and their random effects
red_fighter_df <- data.frame(
R_fighter_id = as.integer(rownames(red_fighter_effects)),
R_fighter_effect = red_fighter_effects[,1]
)
blue_fighter_df <- data.frame(
B_fighter_id = as.integer(rownames(blue_fighter_effects)),
B_fighter_effect = blue_fighter_effects[,1]
)
# Step 9: Add fighter random effects to the original dataset
ufc_model_data_with_effects <- ufc_model_data %>%
left_join(red_fighter_df, by = "R_fighter_id") %>%
left_join(blue_fighter_df, by = "B_fighter_id") %>%
# Fill NAs with 0 (for fighters with no estimated random effect)
mutate(
R_fighter_effect = ifelse(is.na(R_fighter_effect), 0, R_fighter_effect),
B_fighter_effect = ifelse(is.na(B_fighter_effect), 0, B_fighter_effect)
)
# Step 10: Create a new feature that represents the difference in fighter-specific effects
ufc_model_data_with_effects$fighter_effect_diff <-
ufc_model_data_with_effects$R_fighter_effect - ufc_model_data_with_effects$B_fighter_effect
# Step 11: Print some statistics about the random effects
cat("Red fighter random effects summary:\n")
print(summary(red_fighter_df$R_fighter_effect))
cat("\nBlue fighter random effects summary:\n")
print(summary(blue_fighter_df$B_fighter_effect))
cat("\nFighter effect difference summary:\n")
print(summary(ufc_model_data_with_effects$fighter_effect_diff))
# Step 12: Save the enhanced dataset for future logistic regression
write.csv(ufc_model_data_with_effects,
"data/ufc_data_with_fighter_effects.csv",
row.names = FALSE)
# Inform about the created dataset
cat("\nCreated new dataset 'ufc_data_with_fighter_effects.csv' with added columns:\n")
cat("- R_fighter_effect: Random effect for red corner fighter\n")
cat("- B_fighter_effect: Random effect for blue corner fighter\n")
cat("- fighter_effect_diff: Difference in random effects between fighters\n")
cat("\nThis dataset can now be used for logistic regression modeling.\n")
# Step 12: Save the enhanced dataset for future logistic regression
write.csv(ufc_clean_features_effects,
"data/ufc_data_with_fighter_effects.csv",
row.names = FALSE)
# Step 12: Save the enhanced dataset for future logistic regression
write.csv(ufc_model_data_with_effects,
"data/ufc_clean_features_effects.csv",
row.names = FALSE)
# Load necessary libraries
library(tidyverse)
library(glmnet)      # For LASSO regression
library(caret)       # For model training and evaluation
library(pROC)        # For ROC curves
# Read in the feature-engineered dataset
ufc_clean_features_effects <- read.csv("data/ufc_clean_features_effects.csv", stringsAsFactors = FALSE)
# Create list of model features (excluding target variable and identifier variables)
# Note: Adjust this list based on your specific dataset columns
model_features <- c(
# Physical attributes
"height_advantage", "reach_advantage", "age_advantage", "weight_advantage",
# Experience and record
"win_pct_advantage", "experience_diff",
"R_current_win_streak", "B_current_win_streak",
"R_longest_win_streak", "B_longest_win_streak",
# Fighting metrics - differentials
"striking_accuracy_diff", "striking_defense_diff",
"takedown_accuracy_diff", "takedown_defense_diff",
"knockdown_diff", "submission_attempts_diff", "offense_defense_diff",
# Raw metrics - both fighters
"R_avg_SIG_STR_pct", "B_avg_SIG_STR_pct",
"R_avg_TD_pct", "B_avg_TD_pct",
"R_avg_SUB_ATT", "B_avg_SUB_ATT",
"R_avg_KD", "B_avg_KD",
# Style indicators
"R_striking_to_grappling_ratio", "B_striking_to_grappling_ratio"
)
# Create the model dataset with selected features and target
model_data <- ufc_clean_features_effects %>%
select(all_of(c(model_features, "target")))
# Check for and handle any remaining NA values
model_data <- model_data %>% drop_na()
# Read in the feature-engineered dataset
ufc_clean_features_effects <- read.csv("data/ufc_clean_features_effects.csv", stringsAsFactors = FALSE)
